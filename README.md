# Gold-Recovery-Prediction-Via-Regression

![alt image](https://github.com/AeroGenCreator/Gold-Recovery-Prediction-Via-Regression/blob/main/images/cover.jpeg)

## √çndice del Flujo de Trabajo [Estructura del Notebook](https://github.com/AeroGenCreator/Gold-Recovery-Prediction-Via-Regression/blob/main/Proyecto%20Sprint%2013.ipynb)

1. Carga y Preparaci√≥n de Datos:

        Importaci√≥n de librer√≠as, carga de datasets (train, test, full) y tratamiento de valores nulos.

3. Introducci√≥n y Contexto:

        Descripci√≥n del proceso de extracci√≥n de oro.

5. An√°lisis Exploratorio de Datos (EDA):

        Validaci√≥n del c√°lculo de recuperaci√≥n (Recovery).
    
        An√°lisis de la concentraci√≥n de metales (Au, Ag, Pb) por etapa.
    
        Comparaci√≥n de distribuciones de part√≠culas entre entrenamiento y prueba.
    
        Estudio de valores at√≠picos (outliers).

6. Preprocesamiento para Machine Learning:

        Sincronizaci√≥n de caracter√≠sticas entre conjuntos.
    
        Segmentaci√≥n del proceso en dos etapas: Rougher y Final.
    
        Escalado de variables mediante StandardScaler.

7. Desarrollo del Modelo:
    
        Implementaci√≥n de la m√©trica personalizada sMAPE.
    
        Configuraci√≥n de make_scorer para validaci√≥n cruzada.
    
        Entrenamiento y evaluaci√≥n multimodelo (Ridge, Random Forest, Gradient Boosting) usando K-Fold Cross-Validation.

8. Evaluaci√≥n Final y Resultados:
    
       Predicciones en el conjunto de prueba y c√°lculo del sMAPE ponderado final.

10. Conclusiones y Exportaci√≥n:
   
        Resumen de hallazgos y persistencia de modelos/objetos.

## Optimizaci√≥n de la Recuperaci√≥n de Oro mediante Machine Learning

![alt image](https://github.com/AeroGenCreator/Gold-Recovery-Prediction-Via-Regression/blob/main/images/snap_1.png)

## [DASHBOARD](https://gold-recovery-prediction-via-regression.onrender.com)

üìù Descripci√≥n del Proyecto

Este proyecto simula el proceso tecnol√≥gico de extracci√≥n de oro de la miner√≠a real. El objetivo es predecir la cantidad de oro recuperado del mineral de oro mediante modelos de regresi√≥n, optimizando la eficiencia de la planta de producci√≥n y ayudando a descartar par√°metros desfavorables.
üìä Puntos Clave del An√°lisis (EDA)

    Din√°mica de los Metales: Se visualiz√≥ c√≥mo la concentraci√≥n de Oro (Au) aumenta linealmente conforme avanza el 
    proceso (Rougher -> Primary Cleaner -> Final), mientras que otros metales como la Plata (Ag) disminuyen.

    Consistencia de Datos: Se realiz√≥ un an√°lisis de distribuci√≥n de part√≠culas para asegurar que el conjunto de 
    entrenamiento y prueba fueran estad√≠sticamente comparables, garantizando la fiabilidad del modelo.

    Tratamiento de Datos Reales: Limpieza de valores ausentes basados en la continuidad del proceso tecnol√≥gico.

‚öôÔ∏è Implementaci√≥n T√©cnica Relevante
1. M√©trica Personalizada: sMAPE

Para este proyecto, se implement√≥ el Error Medio Absoluto Porcentual Sim√©trico (sMAPE). A diferencia del MAE convencional, el sMAPE es ideal para comparar errores en diferentes escalas de valores.

$$ sMAPE = \frac {1}{N} \sum_{i=1}^N \frac {|y - \hat{y}_i|}{(|y|+|\hat{y}_i|)}$$

Se integr√≥ en el ecosistema de Scikit-Learn utilizando `make_scorer`, permitiendo su uso directo en funciones de optimizaci√≥n.
2. Evaluaci√≥n Multimodelo con Cross-Validation

No nos conformamos con un solo algoritmo. Implementamos una estrategia de K-Fold Cross-Validation (6 splits) para evaluar:

    Ridge Regression

    Random Forest Regressor

    Gradient Boosting Regressor

üèÜ Resultados Finales

El modelo final se construy√≥ bajo un esquema de dos etapas (Rougher y Final), logrando un desempe√±o excepcional:

    sMAPE Etapa Rougher: 0.72%

    sMAPE Etapa Final: 1.44%

    sMAPE Ponderado Final: 1.26% üöÄ

Este bajo error porcentual demuestra la robustez de los modelos (especialmente Gradient Boosting) para predecir la recuperaci√≥n con alta precisi√≥n.

üõ†Ô∏è Tecnolog√≠as Utilizadas

    Python: Pandas, NumPy, Scipy.

    Visualizaci√≥n: Seaborn, Matplotlib.

    Machine Learning: Scikit-Learn (StandardScaler, Cross-validation, GradientBoosting).

    Model Deployment Ready: Exportaci√≥n de modelos y escaladores mediante joblib.
